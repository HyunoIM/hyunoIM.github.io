---
layout: single
title:  "[CS231n] 5. Convolutional Neural Networks"
categories: cs231n
---



# 5.Convolutional Neural Networks 정리





## Convolution Layer

<img width="850" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/a456dd67-c378-46d4-8e3b-3bb655d738ad">
Convolution Layer 에서 필터를 이미지 위에 컨볼루션 시킨다. 이미지를 슬라이드 하면서 dot product 연산을 한다.




<img width="877" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/f6efef2a-f4d2-4d63-949b-d7dcc4032f0b">

Input 이미지와  filter의 depth는 같다. 필터가 쭉 훑어서 진행하는데 한 로케이션 당 하나의 숫자를 생성한다.

새로 생성된 매트릭스를 activation map이라 한다. 하나의 필터는 하나의 activation map를 생성한다. 6개의 필터가 있으면 6개의 activation map이 생성된다.



<img width="915" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/05f3b566-73c5-4b7f-96b7-875613ea2ace">

 새로운 형태의 이미지로 re-representation 한다고 표현한다. activation map이 또 다시 다음 과정을 진행하는 방식이 cnn의 기본적인 형식이다.



<img width="887" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/14083d59-36cc-497b-a323-6e64de1a037a">

이미지 바로 다음의 convolution layer에는 엣지,컬러 등의 블록이 보이고 중간단계에는 블록 하나하나들을 통합한 형태로 볼 수 있다. 뒤쪽 깊은 레이어에서는 상위레벨의 이미지가 보인다. 각 필터는 앞 단의 필터를 기반하여 시각화 한 것이다. 



<img width="716" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/fdd93998-e1fe-4fb9-82ca-5615a74c13bb">

<img width="619" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/302ee731-3558-4b4f-9eeb-0a155ec8aa1f">

<img width="428" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/1e68a32a-968f-4c4a-a562-25ca9927f3e2">

예시의 input은 7x7이고 fiter는 3x3이다. 3x3 필터가 하나씩 훑기 때문에 결과적으로. Activation map은 5x5의 크기를 가진다.



<img width="866" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/eba02df2-a54f-461a-a677-f5061f71f2ce">

Stride는 fiter가 훑을 때 간격을 말한다. Stride가 커지면 activation map의 크기는 작아진다.



## Padding

<img width="848" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/e20ca8a2-26f8-4b4d-bede-6de00966c72f">

패딩을 쓰게되면 사이즈를 보존할 수 있다. 주변 둘레에 0값으로 패딩처리를 한다. 사이즈에 신경쓰지 않고 convoiusion할 수 있게 해준다.

이 강좌에서는 소개되지 않지만 패딩을 꼭 0으로만 하지 않는다. 다양한 방법의 패딩이 존재한다.

수백개에서 수만개의 레이어 처리를 하는데 사이즈가 보존이 되지 않으면 컨볼루션 진행이 불가능하다. 사이즈를 줄이는 작업은 Pooling layer에서 진행한다.



Convolusion 과정에서는 필터의 개수, 필터의 크기, stride, 패딩 4개 하이퍼 파라미터가 필요하다.



뉴런의 관점에서 봤을 때

activation map에 있는 각각의 뉴런은 모두 앞쪽 레이어(입력값)의 일부 지역에 연결 되어있다. 그리고 각각의 뉴런들이 동일한 파라미터를 공유한다. 동일한 파라미터를 가지는 필터를 거치기 때문이다. 이를 파라미터 쉐어링이라고 한다.



<img width="880" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/1ca6e742-77cc-488e-a7d5-f4a86730eea7">

필터가 5개인 경우를 봤을 때 activation map의 뎁스가 5가 되게 되고 각 activation map에서 같은 위치에 있는 뉴런들은 input 이미지의 동일한 위치에 연결되어있고 반면에 각각 다른 activation map에 속하기 때문에 weight는 다르다. 동일한 뎁스 내의 뉴런들은 파라미터 쉐어링을 한다.



## Pooling

<img width="882" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/dd9af56e-4e35-49f8-852d-f01622242100">

Convolution layer는 사이즈를 보존하기 때문에 pooling layer로 사이즈를 줄여준다. 이를 다운샘플링이라고 한다. 

각각의 activation map에 독립적으로 작용하고 뎁스는 유지된다. 사이즈는 풀링 레이어에서 관리한다.



<img width="858" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/192dce03-839e-4b55-9bc1-2c583c528cff">

Max pooling은 Pooling의 한 예시이다.

nxn의 크기로 나누어 주고 각 범위 속 가장 큰 값을 취한다. 역설같지만 맥스풀링을 해서 정보손실이 일어나도 invariance를 얻을 수 있다.

필터의 크기, 스트라이드 두가지의 파라미터만 필요하다.



<img width="849" alt="image" src="https://github.com/JDVVd/deeplearning_with_python/assets/155535882/f49b0487-330a-4b2f-b5b6-6efff0e99d1c">

위 그림은 간단한 CNN의 절차를 보여준다.

Conv, Relu 반복하다가 마지막에 fully connected layer로 클래스의 스코어를 계산. 이 예시에서는 softmax함수를 적용했다.
